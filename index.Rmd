---
title: "Practical Machine Learning"
output: html_document
---

# Load the testing and training dataset and libraries that are needed for modeling

We first load the test and training datasets in R:

```{r cache=TRUE}
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

We load the necessary R packages as follows:

```{r}
library(caret)
library(ggplot2)
library(corrplot)
library(DT)
```

# Exploratory analysis on variables in the data sets

We first looked at a summary of the training dataset:

```{r}
datatable(summary(training))
```

Looking at the summary, we found that there are a few variables with single values or have large number of NA's. Given that these variables do not provide much information, we dropped them from the training set:

```{r}
training <- training[c('new_window', 
                       'num_window',
                       'roll_belt',
                       'pitch_belt',
                       'yaw_belt',
                       'total_accel_belt',
                       'gyros_belt_x',
                       'gyros_belt_y',
                       'gyros_belt_z',
                       'accel_belt_x',
                       'accel_belt_y',
                       'accel_belt_z',
                       'magnet_belt_x',
                       'magnet_belt_y',
                       'magnet_belt_z',
                       'roll_arm',
                       'pitch_arm',
                       'yaw_arm',
                       'total_accel_arm',
                       'gyros_arm_x',
                       'gyros_arm_y',
                       'gyros_arm_z',
                       'accel_arm_x',
                       'accel_arm_y',
                       'accel_arm_z',
                       'magnet_arm_x',
                       'magnet_arm_y',
                       'magnet_arm_z',
                       'roll_dumbbell',
                       'pitch_dumbbell',
                       'yaw_dumbbell',
                       'total_accel_dumbbell',
                       'gyros_dumbbell_x',
                       'gyros_dumbbell_y',
                       'gyros_dumbbell_z',
                       'accel_dumbbell_x',
                       'accel_dumbbell_y',
                       'accel_dumbbell_z',
                       'magnet_dumbbell_x',
                       'magnet_dumbbell_y',
                       'magnet_dumbbell_z',
                       'roll_forearm',
                       'pitch_forearm',
                       'yaw_forearm',
                       'total_accel_forearm',
                       'gyros_forearm_x',
                       'gyros_forearm_y',
                       'gyros_forearm_z',
                       'accel_forearm_x',
                       'accel_forearm_y',
                       'accel_forearm_z',
                       'magnet_forearm_x',
                       'magnet_forearm_y',
                       'magnet_forearm_z',
                       'classe'
                       )]

datatable(summary(training))
```

The only categorical variable in the dataset is 'new_window' with two levels. We can convert it into numeric as follows:

```{r}
training$new_window <- as.numeric(training$new_window == 'yes')
```

We then looked at the correlations between each variables:

```{r}
corrplot(cor(subset(training, select = - c(classe))))
```

Looking at the correlation plot, we can see that there are a few variables that are highly correlated. 

We then did a PCA to help us reduce the number of predictors.

```{r}
p <- preProcess(subset(training, select=-c(classe)), thresh = 0.95)
p
```

So we will need to keep 26 variables to maintain 95% of the variations in the original dataset.

# Data Modeling

We trained the model with different approaches: Random Forest, and Boosted Logistic Regression.

```{r results='hide'}
rf <- train(classe ~ ., 
            data=training, 
            method = 'rf',
            trControl = trainControl(method='oob'),
            ntree = 1000
            )
```

Accuracy of the Random Forest model:

```{r}
rf_results <- rf$results
datatable(rf_results)
```

```{r results='hide'}
logit_fit <- train(classe ~ ., 
             data=training, 
             preProcess = c('scale', 'center', 'pca'),
             thresh = 0.9, 
             trControl = trainControl(method='cv'),
             method = 'LogitBoost'
)
```


```{r}
logit_results <- logit_fit$results
datatable(logit_results)
```

Clearly, the model generated by Random Forest is best in terms of accuracy. The Random Forest model also took significantly more time to train.


The accuracy of the random forest based model is ~0.99 based on cross validation, and we expect the accuracy on the test set to be lower. 

The accuracy of the logistic regression based model is ~0.63 based on cross validation, and we also expect it to be lower when applied to the test set.


Apply it to the testing set:

```{r}
testing$new_window <- as.numeric(testing$new_window == 'yes')
result <- predict(rf, testing)
```
